{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186be3d3",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6269f1",
   "metadata": {},
   "source": [
    "Name: Parshva Bhadra<br>\n",
    "Roll Number: 2020101001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeabff5",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Use the code below to load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69cac090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0fa6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "iris = pd.read_csv('Iris.csv')\n",
    "#data cleaning\n",
    "iris.drop(columns=\"Id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ca8135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features and labels\n",
    "X=iris.iloc[:,0:4].values\n",
    "y=iris.iloc[:,4].values\n",
    "\n",
    "y[y=='Iris-setosa']=0\n",
    "y[y=='Iris-versicolor']=1\n",
    "y[y=='Iris-virginica']=2\n",
    "y=y.astype(int)\n",
    "\n",
    "X=X.astype(float)\n",
    "\n",
    "#Train and Test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14014cb",
   "metadata": {},
   "source": [
    "Write your Code below for KNN Classifier.<br>\n",
    "Use different values of K and test the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ca8c19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     k  accuracy\n",
      "0    1  1.000000\n",
      "1    2  0.966667\n",
      "2    3  1.000000\n",
      "3    4  1.000000\n",
      "4    5  1.000000\n",
      "5    6  1.000000\n",
      "6    7  1.000000\n",
      "7    8  1.000000\n",
      "8    9  1.000000\n",
      "9   10  1.000000\n",
      "10  11  1.000000\n",
      "11  12  1.000000\n",
      "12  13  1.000000\n",
      "13  14  1.000000\n",
      "14  15  1.000000\n",
      "15  16  1.000000\n",
      "16  17  1.000000\n",
      "17  18  1.000000\n",
      "18  19  1.000000\n",
      "19  20  1.000000\n",
      "20  21  1.000000\n",
      "21  22  1.000000\n",
      "22  23  1.000000\n",
      "23  24  1.000000\n",
      "24  25  1.000000\n",
      "25  26  1.000000\n",
      "26  27  1.000000\n",
      "27  28  1.000000\n",
      "28  29  0.966667\n",
      "29  30  0.966667\n",
      "30  31  0.966667\n",
      "31  32  0.966667\n",
      "32  33  0.966667\n",
      "33  34  0.966667\n",
      "34  35  0.966667\n",
      "35  36  0.966667\n",
      "36  37  0.966667\n",
      "37  38  0.966667\n",
      "38  39  0.966667\n",
      "39  40  0.966667\n",
      "40  41  0.966667\n",
      "41  42  0.966667\n",
      "42  43  0.966667\n",
      "43  44  0.966667\n",
      "44  45  0.966667\n",
      "45  46  0.966667\n",
      "46  47  0.966667\n",
      "47  48  0.966667\n",
      "48  49  0.966667\n",
      "49  50  1.000000\n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "for i in range(np.size(X,1)):\n",
    "    X_train[:,i] = X_train[:,i]/np.max(X_train[:,i])\n",
    "    X_test[:,i] = X_test[:,i]/np.max(X_test[:,i])\n",
    "\n",
    "#KNN\n",
    "k_range = 50\n",
    "accuracy = np.zeros(k_range)\n",
    "\n",
    "for k in range(1,k_range+1):\n",
    "    for i in range(np.size(y_test)):\n",
    "        dist = np.sqrt(np.sum(np.square(X_train-X_test[i,:]),axis=1))\n",
    "        ind = np.argsort(dist)\n",
    "        k_nearest = y_train[ind[0:k]]\n",
    "        y_pred = np.argmax(np.bincount(k_nearest))\n",
    "        accuracy[k-1] += (y_pred==y_test[i])\n",
    "\n",
    "accuracy = accuracy/np.size(y_test)\n",
    "\n",
    "df = pd.DataFrame({'k':range(1,k_range+1),'accuracy':accuracy})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ac0ca",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1) What are the Advantages and Disadvantages of KNN algorithm?\n",
    "2) What is the complexity of the KNN algorithm during Training and Testing?\n",
    "3) Is euclidian distance the only distance metric used in KNN? \n",
    "4) what K value gave the best accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43dac",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "1)  * The advantages of using KNN algorithm are as follows:<br><br>\n",
    "        * It is easy to implement.\n",
    "        * Training time is basically nothing.\n",
    "        * It is easy to explain the logic behind the algorithm.\n",
    "        * Error rate is atmost twice the rate of ideal classifier.<br><br>\n",
    "    * The disadvantages of using KNN algorithm are as follows:<br><br>\n",
    "        * Error rate is atmost twice the rate of ideal classifier.\n",
    "        * Testing time is high. So, it is not suitable for large datasets.\n",
    "        * Based on the assumption that similar things exist in close proximity.\n",
    "        * It does not work well with high dimensionality as this will complicate the distance calculating process to calculate distance for each dimension.\n",
    "<br><br><br>\n",
    "2)  * The complexity of KNN algorithm during training is O(1) as it is just storing the data.\n",
    "    * The complexity of KNN algorithm during testing is O(d.n.log(k)) as it is just comparing the data. Here, d is the dimension of the data, n is the number of data points and k is the number of nearest neighbours. This is because we are sorting the data points based on the distance from the test point.\n",
    "<br><br><br>\n",
    "3)  * No, euclidian distance is not the only distance metric used in KNN. Other distance metrics like manhattan distance, minkowski distance, etc. can also be used.\n",
    "<br><br><br>\n",
    "4)  * The K value that gave the best accuracy was 1.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
